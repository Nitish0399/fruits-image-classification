{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Fruits 360\n\nfrom keras.preprocessing.image import ImageDataGenerator\n\ntrain_datagen = ImageDataGenerator(\n        rescale=1./255,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True)\n\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\ntraining_set = train_datagen.flow_from_directory('../input/fruits/fruits-360/Training',\n                                                  target_size=(64, 64),\n                                                  batch_size=64,\n                                                  class_mode='categorical')\n\ntest_set = test_datagen.flow_from_directory('../input/fruits/fruits-360/Test',\n                                             target_size=(64, 64),\n                                             batch_size=64,\n                                             class_mode='categorical')\n\n# print(training_set.class_indices.keys())\n\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import Flatten\nfrom keras.layers import Dense\n\n# Initialising the CNN\nclassifier = Sequential()\n\n# Step 1 - Convolution\nclassifier.add(Conv2D(32,(3, 3),input_shape=(64, 64, 3), activation = 'relu'))\n\n# Step 2 - Pooling\nclassifier.add(MaxPooling2D(pool_size = (2, 2)))\n\n# Adding a second convolutional layer to improve accuracy\nclassifier.add(Conv2D(32,(3, 3), activation = 'relu'))\nclassifier.add(MaxPooling2D(pool_size = (2, 2)))\n\n# Step 3 - Flattening\nclassifier.add(Flatten())\n\n# Step 4 - Full Connection\nclassifier.add(Dense(units = 256, activation = 'relu'))\nclassifier.add(Dense(units = 131, activation = 'sigmoid'))\n\n# Compiling the CNN\nclassifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n\nclassifier.summary()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier.fit_generator(training_set,\n                         steps_per_epoch=60,\n                         epochs=8,\n                         validation_data=test_set,\n                         validation_steps=22688)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"from keras.preprocessing import image\nimg = image.load_img(path= '../input/fruits/fruits-360/Training/Corn/0_100.jpg',target_size=(64,64,3))\nimg = image.img_to_array(img)\ntest_img = img.reshape((1,64,64,3))\nimg_class = classifier.predict_classes(test_img)\nprediction = img_class[0]\nprint(img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classes = training_set.class_indices\nprint(classes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"classifier.save('fruit_model.h5')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow import keras\nload = keras.models.load_model('../input/fruit-model/fruit_model.h5')\nload.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing import image\nimg = image.load_img(path= '../input/classes/litchi.jpg',target_size=(64,64,3))\nimg = image.img_to_array(img)\nimg /= 255.\ntest_img = img.reshape((1,64,64,3))\nimg_class = load.predict_classes(test_img)\nprediction = img_class[0]\nprint(prediction)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}